include:
#  - remote: 'https://gitlab.com/yesolutions/gitlab-ci-templates/raw/main/templates/pre-commit-autofix.yaml'
  - project: "dl/devops/gitlab-ci-slurm"
    ref: master
    file: "/.gitlab-ci.yml"
  - /ci/common.yml
  - /ci/template.yml
  - /ci/benchmark.yml
  - /ci/rules.gitlab_ci.yml

nightly_build_all:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${IMAGE_ALL}
    DOCKER_FILE: dockerfile.ctr
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_sok_tf2:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${IMAGE_SOK_TF2}
    DOCKER_FILE: dockerfile.tf
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_sok_tf1:
  extends: .build_nightly_tf1
  variables:
    DST_IMAGE: ${IMAGE_SOK_TF1}
    DOCKER_FILE: Dockerfile.sok1
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_unified_container.tf:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${CI_REGISTRY}/dl/hugectr/hugectr:unified.tf.latest
    DOCKER_FILE: dockerfile.tf
    BUILD_ARGS: --build-arg _CI_JOB_TOKEN=${RD_CI_JOB_TOKEN} --build-arg _HUGECTR_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr.git --build-arg HUGECTR_VER=${CI_COMMIT_BRANCH}

nightly_build_unified_container.ctr:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${CI_REGISTRY}/dl/hugectr/hugectr:unified.ctr.latest
    DOCKER_FILE: dockerfile.ctr
    BUILD_ARGS: --build-arg _CI_JOB_TOKEN=${RD_CI_JOB_TOKEN} --build-arg _HUGECTR_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr.git --build-arg HUGECTR_VER=${CI_COMMIT_BRANCH} --build-arg _HUGECTR_BACKEND_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr_inference_backend.git --build-arg HUGECTR_BACKEND_VER=hugectr_performance_test

nightly_build_optimized:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://${RD_CI_JOB_TOKEN}gitlab-master.nvidia.com/dl/mlperf/optimized.git
    DST_IMAGE: ${IMAGE_OPTIMIZED}
    DOCKER_FILE: Dockerfile
    BUILD_ARGS: --build-arg RELEASE=false --build-arg FROM_IMAGE_NAME=gitlab-master.nvidia.com:5005/dl/dgx/pytorch:master-py3-devel
    OPTIMIZED: 1
  rules:
    - if: $NIGHTLY_OPTIMIZED == "1"
      when: always
    - when: never

build_optimized:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://${RD_CI_JOB_TOKEN}gitlab-master.nvidia.com/dl/mlperf/optimized.git
    DST_IMAGE: ${IMAGE_OPTIMIZED}
    DOCKER_FILE: Dockerfile
    BUILD_ARGS: --build-arg FROM_IMAGE_NAME=gitlab-master.nvidia.com:5005/dl/dgx/pytorch:master-py3-devel
    OPTIMIZED: 1
  rules:
    - if: $NIGHTLY_OPTIMIZED == "1"
      when: always
    - when: never

### Stage: build
format_check_python:
  extends: .python_format
  variables:
    EXCLUDE: "third_party|docs|notebooks|tutorial"

format_check_clang:
  extends: .clang_format
  variables:
    EXCLUDE: ./third_party
    STYLE: file
    EXECUTABLE: clang-format14
    EXTENSIONS: "h,hpp,cpp,cu,cuh"

codespell_check:
  extends: .codespell_check
  variables:
    PRE_COM_IMAGE: registry.gitlab.com/yesolutions/docker-pre-commit

build_train_single_node:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_latest:
  extends: .build_hugectr_daily
  variables:
    FROM_IMAGE: ${MERLIN_NIGHTLY_DEVEL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED_LATEST
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_hdfs_minimal:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED_WITH_HDFS_MINI
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF -DENABLE_HDFS=MINIMAL"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_hdfs_full:
  extends: .build_hugectr_daily
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED_WITH_HDFS
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF -DENABLE_HDFS=ON"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_s3:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: ${TRAIN_IMAGE_VERSIONED_WITH_S3}
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF -DENABLE_S3=ON"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_gcs:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: ${TRAIN_IMAGE_VERSIONED_WITH_GCS}
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF -DENABLE_GCS=ON"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_multi_node:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_MULTINODE_VERSIONED
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DENABLE_MULTINODES=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1

build_train_inference:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_INFER_IMAGE_VERSIONED
    CMAKE_OPTION: "-DENABLE_INFERENCE=ON -DCMAKE_BUILD_TYPE=Release -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1

### Stage: test
build_inference:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $INFER_IMAGE_VERSIONED
    CMAKE_OPTION: "-DENABLE_INFERENCE=ON -DCMAKE_BUILD_TYPE=Release -DSM=\"70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HPS_BACKEND: 1
    HUGECTR_BACKEND_VER: main
    TRITON_BRANCH: ${TARGET_TRITON_BRANCH}

build_sok_tf2:
  extends: .build_sok
  variables:
    FROM_IMAGE: ${IMAGE_SOK_TF2}
    DST_IMAGE: $SOK_IMAGE_VERSIONED_TF2
    CMAKE_OPTION: "-DSM=\"60;61;70;75;80;90\""
    BUILD_SOK: 1

build_sok_tf1:
  extends: .build_sok
  variables:
    FROM_IMAGE: ${IMAGE_SOK_TF1}
    DST_IMAGE: $SOK_IMAGE_VERSIONED_TF1
    CMAKE_OPTION: "-DSM=\"60;61;70;75;80;90\""
    BUILD_SOK: 1

build_hugectr_hps_trt_plugin:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $HUGECTR_TRT_IMAGE_VERSIONED
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1
    BUILD_TRT_PLUGIN: 1
    TRT_CMAKE_OPTION: "-DSM=\"70;75;80;90\""
    #BUILD_HPS_BACKEND: 1
    #HUGECTR_BACKEND_VER: main
    #TRITON_BRANCH: ${TRITON_BRANCH}

build_tf_hps_trt_plugin:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_SOK_TF2}
    DST_IMAGE: $TF_TRT_IMAGE_VERSIONED
    BUILD_TF_PLUGIN: 1
    BUILD_TRT_PLUGIN: 1
    TRT_CMAKE_OPTION: "-DSM=\"70;75;80;90\""
    #BUILD_HPS_BACKEND: 1
    #HUGECTR_BACKEND_VER: main
    #TRITON_BRANCH: r22.11

build_pytorch_hps_trt_plugin:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_PYTORCH}
    DST_IMAGE: $PYTORCH_TRT_IMAGE_VERSIONED
    BUILD_TORCH_PLUGIN: 1    
    BUILD_TRT_PLUGIN: 1
    TRT_CMAKE_OPTION: "-DSM=\"70;75;80;90\""
    #BUILD_HPS_BACKEND: 1
    #HUGECTR_BACKEND_VER: main
    #TRITON_BRANCH: r22.11

# Check Selene busy or not
check_selene_status:
  extends: .trigger:rules:selene
  stage: pre_test
  tags:
    - nvidia.com/cuda.driver.major=470
    - $BUILD_TAG
  script:
    - docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}"
    - docker pull ${CONT}
    - RC=0
    - docker run -d --rm --name selene_idle_${CI_PIPELINE_ID} ${EXTRA_DOCKER_RUN_ARGS} ${CONT} sleep infinity
    - docker exec selene_idle_${CI_PIPELINE_ID} bash -cx "python get_selene_runner_status.py --quota ${SELENE_QUEUE_QUOTA} --token \"${CLUSTER_TOKEN}\" " || RC=$?
    - echo "$RC"
    - echo "NEW_CI_CONCURRENT_ID=${CI_CONCURRENT_ID}" >> other_param.env
    - if [[ $RC == 0 ]]; then
      echo "Selene is idle!";
      cp ./ci/selene/ci.yml ./test-ci.yml;
      echo "NEW_SBATCH_OTHER_PARAMS=" >> other_param.env;
      else
      echo "Selene is busy!";
      cp ./ci/dracorno/ci.yml ./test-ci.yml;
      echo "NEW_SBATCH_OTHER_PARAMS=--nv-meta ml-model.hugectr --gpus-per-node=8" >> other_param.env;
      fi
    - cat other_param.env
  artifacts:
    paths:
      - ./test-ci.yml
    reports:
      dotenv: other_param.env
  variables:
    CONT: gitlab-master.nvidia.com:5005/dl/hugectr/hugectr/emma:get_selene_status_new
  allow_failure: false
  timeout: 15 minutes

trigger_test_pipeline:
  extends: .trigger:rules:selene
  stage:
    test
  needs:
    - check_selene_status
  trigger:
    include:
      - artifact: test-ci.yml
        job: check_selene_status
    strategy: depend
  variables:
    PARENT_SOURCE: ${CI_PIPELINE_SOURCE}
    PARENT_PIPELINE_ID: ${CI_PIPELINE_ID}
    GCS_ACCESS_FILE: ${GCS_ACCESS_FILE}
    PARENT_GCS_ACCESS_FILE: ${GCS_ACCESS_FILE}
    SBATCH_OTHER_PARAMS: ${NEW_SBATCH_OTHER_PARAMS}

criteo_multi_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    GPFSFOLDER: $LOGDIR/criteo_multi_node
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DATASET}:${DATASET_MOUNT}
    WALLTIME: "00:15:00"
    DGXNNODES: 2
    TEST_CMD: ./ci/integration_test/criteo/criteo_multi_node.sub

dlrm_benchmark_14node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    GPFSFOLDER: $LOGDIR/dlrm_benchmark_14node
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: /raid:/raid
    WALLTIME: "00:15:00"
    SBATCH_OTHER_PARAMS: --network sharp
    DGXNNODES: 14
    TEST_CMD: ./ci/integration_test/dlrm/benchmark_14node.sub

dlrm_ib_nvlink_1node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    GPFSFOLDER: $LOGDIR/dlrm_ib_nvlink_1node
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: /raid/datasets/criteo/mlperf/40m.limit_preshuffled:/data
    WALLTIME: "00:10:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/integration_test/dlrm/ib_nvlink_1node.sub

dlrm_ib_nvlink_8node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    GPFSFOLDER: $LOGDIR/dlrm_ib_nvlink_8node
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: /raid/datasets/criteo/mlperf/40m.limit_preshuffled:/data
    WALLTIME: "00:10:00"
    SBATCH_OTHER_PARAMS: --comment=metrics
    DGXNNODES: 8
    TEST_CMD: ./ci/integration_test/dlrm/ib_nvlink_8node.sub

dlrm_dcnv2_benchmark_8node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    GPFSFOLDER: $LOGDIR/dlrm_dcnv2_benchmark_8node
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: /lustre/fsw/mlperf/mlperft-dlrm/datasets/criteo_multihot_raw:/data,/lustre/fsw/mlperf/mlperft-dlrm/datasets/criteo_multihot_raw:/data_val
    WALLTIME: "00:15:00"
    DGXNNODES: 8
    TEST_CMD: ./ci/integration_test/dlrm/train_dcnv2_8node.sub

wdl_multi_gpu:
  extends: .cluster_test_job_daily                                                     # test on selene needs to extend .cluster_test_job
  needs:
    - build_train_single_node
  variables:
    GPFSFOLDER: $LOGDIR/wdl_multi_gpu                                                      # log dir, usually $LOGDIR + job name
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}                                     # should not change
    CONT: $TRAIN_IMAGE_VERSIONED                                                 # image name
    MOUNTS: ${DATASET_NEW_CRITEO_SELENE}:${DATASET_MOUNT}                                          # mount
    WALLTIME: "00:15:00"                                                         # estimate job time. Less time, higher priority
    DGXNNODES: 1                                                                 # node num
    TEST_CMD: ./ci/integration_test/wdl/wdl_daily.sub

deepfm_multi_gpu:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    GPFSFOLDER: $LOGDIR/deepfm_multi_gpu
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DATASET}:${DATASET_MOUNT}
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/integration_test/deepfm/deepfm_daily.sub

dcn_multi_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    GPFSFOLDER: $LOGDIR/dcn_multi_node
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DATASET}:${DATASET_MOUNT}
    WALLTIME: "01:00:00"
    DGXNNODES: 4                                                                              # using 4 node
    TEST_CMD: ./ci/integration_test/dcn/dcn_multi_node.sub

py_low_level:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    GPFSFOLDER: $LOGDIR/py_low_level
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: /raid:/raid,${DATASET_NEW_CRITEO_SELENE}:${NEW_CRITEO_MOUNT}
    WALLTIME: "01:00:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/integration_test/py_interface/py_low_level.sub

ebc_single_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    GPFSFOLDER: $LOGDIR/ebc_single_node
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DATASET_NEW_CRITEO_SELENE}:${DATASET_MOUNT},/raid:/raid
    WALLTIME: "00:45:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/integration_test/ebc/ebc.sub

py_multi_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    GPFSFOLDER: $LOGDIR/py_multi_node
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DATASET}:${DATASET_MOUNT}
    WALLTIME: "00:15:00"
    DGXNNODES: 4
    TEST_CMD: ./ci/integration_test/py_interface/py_multi_node.sub

inference_benchmark:
  extends: .cluster_test_job_daily
  needs:
    - build_inference
  before_script:
    - export BZ=1
    - export MIXED_PRECISION=FP32
  variables:
    GPFSFOLDER: $LOGDIR/inference_benchmark
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $INFER_IMAGE_VERSIONED
    MOUNTS: /lustre/fsw/devtech/hpc-hugectr/inference/dlrm_regression/dlrm/1:/model/dlrm/1,/lustre/fsw/devtech/hpc-hugectr/keynote_inference/perf_data:/perf_data
    WORKDIR: /workdir
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/benchmark/inference_benchmark/run.sub

inference_ps_test:
  extends: .computelab_test_job_daily
  allow_failure: false
  stage: test
  needs:
    - build_inference
  script:
    - export CONT=${INFER_IMAGE_VERSIONED}
    - bash ./ci/integration_test/inference/ps_test.sh

inference_embedding_cache_update_test:
  extends: .computelab_test_job_daily
  allow_failure: false
  stage: test
  needs:
    - build_inference
  script:
    - export CONT=${INFER_IMAGE_VERSIONED}
    - bash ./ci/integration_test/inference/embedding_cache_update_test.sh

#hdfs backend test
hdfs_backend_test:
  extends: .computelab_test_job_daily
  needs:
    - build_train_single_node_with_hdfs_full
  script:
    - export CONT=${TRAIN_IMAGE_VERSIONED_WITH_HDFS}
    - bash ./ci/integration_test/hdfs/hdfs_backend_test.sh

continuous_training_inference:
  extends: .test_local
  variables:
    CONT: ${UNIFIED_CTR_LATEST}
    MOUNTS: -v /opt/ci/demo:/scripts -v /opt/ci/wdl_infer:/wdl_infer
    CMD: "apt update -y --fix-missing && apt install bc && cd /scripts && bash run_continuouse_test.sh"

# NVT regression
e2e_nvt_regression_test:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node_latest
  variables:
    GPFSFOLDER: $LOGDIR/e2e_nvt_regression_test
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED_LATEST
    MOUNTS: /lustre/fsw/devtech/hpc-hugectr/criteo_1TB/day_1:/workdir/tools/day_1,/lustre/fsw/devtech/hpc-hugectr/inference/nvt_regression:/workdir/samples/din/raw_data,/lustre/fsw/devtech/hpc-hugectr/criteo_1TB/day_0:/dir/to/criteo/day_0
    WALLTIME: "01:00:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/integration_test/nvt/nvt_regression_test.sub

nb_hps_demo:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    GPFSFOLDER: $LOGDIR/nb_hps_demo
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/integration_test/notebooks/hps_demo.sub

test_sok_pypi:
  extends: .cluster_test_job_daily
  needs:
    - build_sok_tf2
  variables:
    GPFSFOLDER: $LOGDIR/test_sok_pypi
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $SOK_IMAGE_VERSIONED_TF2
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/integration_test/sok/test_sok_pypi.sub

wdl_check:
  # Push logs to gitlab
  extends: .cluster_post_test_job_daily
  needs:
    - wdl_multi_gpu
  variables:
    GPFSFOLDER: $LOGDIR/wdl_check
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: $LOGDIR/wdl_multi_gpu:/logs
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/post_test/check_wdl.sub

inference_benchmark_check:
  extends: .cluster_post_test_job_daily
  needs:
    - inference_benchmark
    - build_train_single_node
  variables:
    GPFSFOLDER: $LOGDIR/inference_benchmark_check
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: $LOGDIR/inference_benchmark:/logs
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/post_test/check_inference_benchmark.sub

inference_cpu_memory_usage:
  extends: .cluster_test_job_daily
  needs:
    - build_inference
  before_script:
    - export BZ=1
    - export MIXED_PRECISION=FP32
  variables:
    GPFSFOLDER: $LOGDIR/inference_cpu_memory
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $INFER_IMAGE_VERSIONED
    MOUNTS: /lustre/fsw/devtech/hpc-hugectr/inference/dlrm_regression/dlrm/1:/model/dlrm/1,$LOGDIR/inference_cpu_memory:/logs
    WORKDIR: /workdir
    WALLTIME: "00:30:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/benchmark/hps_memory_check/run.sub

inference_CPU_Memory_check:
  extends: .cluster_post_test_job_daily
  needs:
    - inference_cpu_memory_usage
    - build_train_single_node
  variables:
    GPFSFOLDER: $LOGDIR/inference_cpu_memory
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: $LOGDIR/inference_cpu_memory:/logs
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/post_test/check_cpu_usage.sub

dlrm_14node_check:
  # Push logs to gitlab
  extends: .cluster_post_test_job_daily
  needs:
    - dlrm_benchmark_14node
  variables:
    GPFSFOLDER: $LOGDIR/dlrm_14node_check
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: $LOGDIR/dlrm_benchmark_14node:/logs
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/post_test/check_dlrm_14node.sub

dlrm_dcnv2_8node_check:
  # Push logs to gitlab
  extends: .cluster_post_test_job_daily
  needs:
    - dlrm_dcnv2_benchmark_8node
  variables:
    GPFSFOLDER: $LOGDIR/dlrm_dcnv2_8node_check
    GIT_CLONE_PATH: ${GIT_CLONE_PATH_SELENE}
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: $LOGDIR/dlrm_dcnv2_benchmark_8node:/logs
    WALLTIME: "00:15:00"
    DGXNNODES: 1
    TEST_CMD: ./ci/post_test/check_dcnv2_dlrm_8node.sub

# rm_logs:
#   extends: .cluster_test_job
#   variables:
#     GPFSFOLDER: "$LOGDIR"
#     GIT_CLONE_PATH: /lustre/fsw/devtech/hpc-hugectr/hugectr-ci/$CI_CONCURRENT_ID/$CI_PROJECT_NAME
#     CONT: $TRAIN_IMAGE_VERSIONED
#     MOUNTS: /lustre/fsw/devtech:/logs
#     SLURM_ACCOUNT: devtech
#     WALLTIME: "00:15:00"
#     DGXNNODES: 1
#     TEST_CMD: ./ci/common/clean_logs.sub

